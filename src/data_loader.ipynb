{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db099f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from torchvision) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: requests in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: torch==1.11.0 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\youngrae\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# Install libraries for data_loader\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install torchvision\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307d1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DataLoader and corresponding libraries\n",
    "import pandas\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88dc1606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for tensors\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824ee728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm for progress bar construction\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18c7f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Datatypes and Devices (from Assignment 2)\n",
    "dtype = torch.float\n",
    "ltype = torch.long\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35cde023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters for K-Fold Cross Validation\n",
    "N = 5\n",
    "seed = 42\n",
    "\n",
    "# Directories for Data\n",
    "FF1010_Path = './data/'\n",
    "AudioImage_Path = './image/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ff2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call StratifiedKFold object\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=5, shuffle=True, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3a6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify dataframe for K-Fold Cross Validation\n",
    "ff1010_csv = pandas.read_csv(FF1010_Path + 'metadata.csv')\n",
    "for i in range(2):\n",
    "    ff1010_csv.loc[ff1010_csv['hasbird'] == 0, 'filepath'] = \\\n",
    "        FF1010_Path + 'nocall/' + ff1010_csv.query('hasbird==0')['filename'] + '.npy'\n",
    "    ff1010_csv.loc[ff1010_csv['hasbird'] == 1, 'filepath'] = \\\n",
    "        FF1010_Path + 'bird/' + ff1010_csv.query('hasbird==1')['filename'] + '.npy'\n",
    "\n",
    "ff1010_csv = ff1010_csv.dropna()\n",
    "ff1010_csv = ff1010_csv.reset_index(drop=True)\n",
    "\n",
    "# Add 'fold' attribute for dataset classification\n",
    "ff1010_dataframe = ff1010_csv.copy()\n",
    "for n, (_, nth_groups) in enumerate(\n",
    "    skf.split(ff1010_dataframe, ff1010_dataframe['hasbird'])):\n",
    "    ff1010_dataframe.loc[nth_groups, 'fold'] = int(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d909d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters for training \n",
    "ff1010_batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c3880f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for FF1010\n",
    "class FF1010(Dataset):\n",
    "    def __init__(self, dataframe, process='train'):\n",
    "        self.dataframe = dataframe\n",
    "        self.filepaths = dataframe['filepath'].values\n",
    "        self.labels = dataframe['hasbird'].values\n",
    "        \n",
    "        # Transforms for each train and validation\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.Resize([128, 281]),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        self.valid_transform = transforms.Compose([\n",
    "            transforms.Resize([128, 281]),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        print(self.filepaths[idx])\n",
    "        source = np.load(self.filepaths[idx])\n",
    "        source = source.transpose(1, 2, 0)\n",
    "        source = np.stack((np.squeeze(source), ) * 3, -1)\n",
    "        \n",
    "        # Apply transform\n",
    "        if process == 'train':\n",
    "            source = self.train_transform(source).to(device)\n",
    "        elif process == 'valid':\n",
    "            source = self.valid_transform(source).to(device)\n",
    "        \n",
    "        return source, torch.tensor(self.labels[idx], dtype=ltype).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c650ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop for nocall detector\n",
    "def nocall_train(train_dataframe, val_dataframe):\n",
    "    train_data = FF1010(train_dataframe, process='train')\n",
    "    val_data = FF1010(val_dataframe, process='valid')\n",
    "    \n",
    "    # Construct data loader for train and validation\n",
    "    train_loader = DataLoader(train_data, batch_size=ff1010_batch,\n",
    "                             shuffle=False, num_workers=4,\n",
    "                             pin_memory=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=ff1010_batch,\n",
    "                             shuffle=False, num_workers=4,\n",
    "                             pin_memory=True, drop_last=False)\n",
    "    \n",
    "#     # Test for loaders\n",
    "#     for index, (source, label) in enumerate(tqdm.tqdm(train_loader)):\n",
    "#         sleep(0.01)\n",
    "    \n",
    "    val_losses = None\n",
    "    train_losses = None\n",
    "    return val_losses, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96067f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Validate and Test for nocall detector\n",
    "def nocall(dataframe, val_index, test_index):\n",
    "    assert val_index != test_index, \\\n",
    "        'Validation and test should be done on different fold.'\n",
    "    train_dataframe = dataframe.query(\n",
    "        'fold != ' + str(val_index) + ' and fold != ' + str(test_index) \n",
    "    ).reset_index(drop=True)\n",
    "    val_dataframe = dataframe.query(\n",
    "        'fold == ' + str(val_index) \n",
    "    ).reset_index(drop=False)\n",
    "    \n",
    "    val_losses, train_losses = nocall_train(train_dataframe, val_dataframe)\n",
    "    return\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf08a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocall(ff1010_dataframe, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # class for Mel-spectrograms\n",
    "# class AudioImage(Dataset):\n",
    "#     def __init__(self, dataframe, process='train'):\n",
    "#         self.dataframe = dataframe\n",
    "#         self.filepaths = dataframe['filepath'].values\n",
    "#         self.labels = dataframe['hasbird'].values\n",
    "        \n",
    "#         # Transforms for each train and validation\n",
    "#         self.train_transform = transforms.Compose([\n",
    "#             transforms.Resize(128, 281),\n",
    "#             transforms.RandomHorizontalFlip(p=0.5),\n",
    "#             transforms.RandomVerticalFlip(p=0.5),\n",
    "#             transforms.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406],\n",
    "#                 std=[0.229, 0.224, 0.225],\n",
    "#             ),\n",
    "#             transforms.ToTensor(),\n",
    "#         ])\n",
    "#         self.valid_transform = transforms.Compose([\n",
    "#             transforms.Resize(128, 281),\n",
    "#             transforms.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406],\n",
    "#                 std=[0.229, 0.224, 0.225],\n",
    "#             ),\n",
    "#             transforms.ToTensor(),\n",
    "#         ])\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         source = np.load(self.filepaths[index]).to(device)\n",
    "#         source = source.transpose(1, 2, 0)\n",
    "#         source = np.stack((np.squeeze(source), ) * 3, -1)\n",
    "        \n",
    "#         # Apply transform\n",
    "#         if process == 'train':\n",
    "#             source = self.train_transform(source)\n",
    "#         elif process == 'valid':\n",
    "#             source = self.valid_transform(source)\n",
    "        \n",
    "#         return source, torch.tensor(self.labels[index], dtype=ltype).to(device)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a19f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
